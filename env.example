# Chrysalis Environment Configuration
# Copy to .env and fill in your values
#
# PROVIDER POLICY:
#   - OpenAI and Anthropic are DEPRECATED
#   - Use OpenRouter as primary provider
#   - Use Ollama for local/offline
#   - Use Cursor Agent for complex reasoning
#

# =============================================================================
# LLM Gateway Configuration
# =============================================================================

# Primary provider: openrouter (recommended), ollama, cursor
LLM_PROVIDER=openrouter

# Default model - GLM4 via OpenRouter
LLM_DEFAULT_MODEL=thudm/glm-4-9b-chat

# Fallback providers (comma-separated)
# Example: ollama,cursor
LLM_FALLBACKS=ollama

# =============================================================================
# Provider API Keys
# =============================================================================

# OpenRouter (PRIMARY - recommended)
# Access GLM4.6-exacto, Mistral, and other models through unified API
OPENROUTER_API_KEY=sk-or-your-key-here

# Mistral (direct API - for Mistral-specific models)
MISTRAL_API_KEY=your-mistral-key-here

# Ollama Local (for offline/fast inference)
OLLAMA_BASE_URL=http://localhost:11434

# Ollama Cloud (optional - for cloud-hosted Ollama)
OLLAMA_CLOUD_API_KEY=your-ollama-cloud-key-here

# Hugging Face (for LLM and embeddings)
HUGGINGFACE_API_KEY=your-hf-key-here
HUGGINGFACE_BASE_URL=  # Optional: for Inference Endpoints

# =============================================================================
# Embedding Configuration
# =============================================================================

# Embedding provider: ollama, huggingface, sentence_transformers, openai
EMBEDDING_PROVIDER=ollama

# Ollama embedding model (local, free)
# Options: nomic-embed-text, mxbai-embed-large, all-minilm, bge-m3
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# HuggingFace embedding model (API)
# Options: sentence-transformers/all-MiniLM-L6-v2, BAAI/bge-base-en-v1.5, nomic-ai/nomic-embed-text-v1.5
HUGGINGFACE_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Embedding cache (SQLite path for persistent cache)
EMBEDDING_CACHE_PATH=./data/embedding_cache.db

# Cursor Agent Adapter (for system agent consultations)
CURSOR_ADAPTER_URL=http://localhost:3210
CURSOR_ADAPTER_PORT=3210
CURSOR_ADAPTER_HOST=127.0.0.1

# =============================================================================
# REMOVED - Keys No Longer Used
# =============================================================================
# OpenAI and Anthropic keys have been removed from this project.
# Access their models via OpenRouter if needed.

# =============================================================================
# Gateway Server
# =============================================================================

GATEWAY_PORT=8080
GATEWAY_AUTH_TOKEN=

# Rate limiting
GATEWAY_RATE_RPS=10
GATEWAY_RATE_BURST=20

# Cost tracking
LLM_DAILY_BUDGET_USD=50
LLM_MONTHLY_BUDGET_USD=500

# Circuit breaker
CIRCUIT_FAILURE_THRESHOLD=3
CIRCUIT_RESET_TIME_MS=60000

# CORS
CORS_ALLOWED_ORIGINS=localhost:3000,localhost:8080

# =============================================================================
# Fireproof Configuration (Local-First CRDT Storage)
# =============================================================================

FIREPROOF_ENABLED=true
FIREPROOF_DB_NAME=chrysalis-memory
FIREPROOF_DB_PATH=./data/fireproof.db

# Sync to central hub
FIREPROOF_SYNC_ENABLED=true
FIREPROOF_SYNC_GATEWAY=ws://localhost:4444
FIREPROOF_SYNC_INTERVAL=60
FIREPROOF_SYNC_BATCH_SIZE=100

# Memory promotion (short-term â†’ long-term)
FIREPROOF_PROMOTION_ENABLED=true
FIREPROOF_PROMOTION_THRESHOLD=0.7

# Local vector caching
FIREPROOF_LOCAL_VECTORS=true

# =============================================================================
# Chrysalis Sync Hub (Central Server)
# =============================================================================

SYNC_HUB_PORT=4444
SYNC_HUB_HTTP_PORT=8082
COLLECTIVE_DB_PATH=./data/collective_memory.db
VECTOR_INDEX_TYPE=hnsw
VECTOR_DIMENSIONS=768

# =============================================================================
# Gossip Protocol Configuration
# =============================================================================

GOSSIP_FANOUT=3
GOSSIP_INTERVAL_MS=500
GOSSIP_ANTI_ENTROPY_ENABLED=true
GOSSIP_ANTI_ENTROPY_INTERVAL_MS=5000

# =============================================================================
# Development
# =============================================================================

NODE_ENV=development
DEBUG=chrysalis:*
