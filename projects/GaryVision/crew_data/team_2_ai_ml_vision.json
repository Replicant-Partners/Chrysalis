{
  "team_id": "team_2",
  "team_name": "AI/ML Vision",
  "description": "Implement AI models, creative loop engine, and vision-language integration",
  "phase": "Phase 1-3: Foundation, Model Integration, Creative Loop",
  "agents": [
    {
      "id": "ai_ml_agent_1",
      "name": "Dr. Wei Zhang",
      "role": "Model Deployment Architect",
      "expertise": ["Model versioning", "Stable Diffusion", "ONNX optimization", "Hardware-adaptive AI"],
      "assignments": ["T2-001", "T2-004", "T2-005"],
      "personality": {
        "origin": "ML engineer who learned open source models can match proprietary ones with proper optimization",
        "mantra": "Open source enables innovation. Quantization enables access. Performance enables adoption.",
        "obsession": "Model performance benchmarks - tracks inference time across hardware tiers"
      }
    },
    {
      "id": "ai_ml_agent_2",
      "name": "Face Recognition Specialist",
      "role": "Privacy-First Vision Engineer",
      "expertise": ["InsightFace", "Face embeddings", "Privacy-preserving ML", "GDPR compliance"],
      "assignments": ["T2-007"],
      "personality": {
        "origin": "Computer vision specialist focused on privacy-first face recognition",
        "mantra": "Privacy is not optional. Encryption is essential. Consent is required.",
        "obsession": "Face detection accuracy - >95% for clear faces, encrypted at rest"
      }
    },
    {
      "id": "ai_ml_agent_3",
      "name": "Object Detection Specialist",
      "role": "YOLO Vision Engineer",
      "expertise": ["YOLOv8", "Object detection", "ONNX Runtime", "Real-time inference"],
      "assignments": [],
      "personality": {
        "origin": "Real-time vision specialist optimizing for elder-relevant objects",
        "mantra": "Speed enables experience. Accuracy builds trust. Objects tell stories.",
        "obsession": "Detection speed - <100ms per image on all hardware"
      }
    },
    {
      "id": "ai_ml_agent_4",
      "name": "Prompt Engineering Specialist",
      "role": "LLM Integration & Calibration Expert",
      "expertise": ["LLaVA", "Prompt engineering", "Confidence calibration", "Model behavior"],
      "assignments": ["T2-006"],
      "personality": {
        "origin": "NLP specialist who understands that prompt quality determines output quality",
        "mantra": "Prompts are programming. Context is control. Calibration is honesty.",
        "obsession": "Confidence calibration - reported 0.90 should mean actual 0.88-0.92"
      }
    },
    {
      "id": "ai_ml_agent_5",
      "name": "Alex Rivera",
      "role": "ML Optimization Specialist",
      "expertise": ["Type hints", "Hardware detection", "Performance optimization", "NumPy/PIL"],
      "assignments": ["T2-002", "T2-003"],
      "personality": {
        "origin": "Performance engineer who optimizes every millisecond",
        "mantra": "Cache once, use forever. Type safety prevents bugs. 99% improvement matters.",
        "obsession": "Performance metrics - turned 160ms into <1ms with caching"
      }
    }
  ],
  "tasks": [
    {
      "id": "T2-001",
      "title": "Implement Model Versioning System",
      "week": 1,
      "priority": "P0_CRITICAL",
      "agent": "ai_ml_agent_1",
      "description": "Track model versions for reproducibility and embedding compatibility",
      "deliverables": [
        "backend/ai/model_registry.py (registry with versions, hashes)",
        "backend/ai/version_checker.py (compatibility checks)",
        "backend/database/migrations/add_model_version_to_embeddings.sql",
        "scripts/migrate_embeddings.py (migration tool)",
        "Documentation: Model versioning guide"
      ],
      "success_criteria": [
        "All models have versions tracked",
        "Embeddings store model version in metadata",
        "Version mismatch warnings logged",
        "Migration tool tested with 1000 embeddings"
      ],
      "confidence": 90,
      "dependencies": []
    },
    {
      "id": "T2-002",
      "title": "Add Type Hints to AI/ML Services",
      "week": 2,
      "priority": "P0_CRITICAL",
      "agent": "ai_ml_agent_5",
      "description": "Add comprehensive type hints to AI/ML code for 95%+ coverage",
      "deliverables": [
        "backend/services/inference/*.py (all files typed with NumPy/PIL types)",
        "backend/services/*_service.py (AI/ML services typed)",
        "mypy.ini (updated for NumPy/PIL)",
        "tests/type_checking/test_ai_types.py",
        "Documentation: AI/ML type hints guide"
      ],
      "success_criteria": [
        "mypy backend/services/inference/ --strict: 0 errors",
        "Type coverage ≥95%",
        "All NumPy/PIL types properly annotated"
      ],
      "confidence": 85,
      "dependencies": ["T2-001"]
    },
    {
      "id": "T2-003",
      "title": "Cache Hardware Detection Results",
      "week": 1,
      "days": "3-5",
      "priority": "P1_HIGH",
      "agent": "ai_ml_agent_5",
      "description": "Cache hardware detection to avoid 160ms repeated checks (99% improvement)",
      "deliverables": [
        "backend/ai/hardware.py (cached detection with @lru_cache, HardwareTier enum)",
        "backend/api/main.py (detect at startup, log tier)",
        "tests/unit/test_hardware_cache.py",
        "Performance benchmarks: 160ms → <1ms"
      ],
      "success_criteria": [
        "Hardware detected once at startup",
        "Subsequent calls <1ms (cached)",
        "Performance: 160ms → <1ms (99% improvement)"
      ],
      "confidence": 99,
      "dependencies": [],
      "parallel": true
    },
    {
      "id": "T2-004",
      "title": "Integrate Stable Diffusion",
      "week": "5-6",
      "priority": "P0_CRITICAL",
      "agent": "ai_ml_agent_1",
      "description": "Integrate Stable Diffusion 1.5 for text-to-image generation with hardware-adaptive implementation",
      "deliverables": [
        "backend/services/inference/stable_diffusion.py (SD service)",
        "backend/services/inference/sd_cloud_fallback.py (Replicate/Together AI)",
        "backend/ai/safety_filter.py (NSFW detection)",
        "models/stable_diffusion/ (model files or download script)",
        "tests/integration/test_sd_generation.py",
        "Documentation: SD usage guide"
      ],
      "success_criteria": [
        "Local generation <10s (GPU)",
        "Cloud fallback works (CPU-only systems)",
        "Safety filter blocks NSFW",
        "Integration with creative loop ready"
      ],
      "confidence": 85,
      "dependencies": ["T2-003"]
    },
    {
      "id": "T2-005",
      "title": "Implement Creative Loop Engine",
      "week": "7-9",
      "priority": "P0_CRITICAL",
      "agent": "ai_ml_agent_1",
      "description": "Implement creative loop: image→text→image remixing (3 iterations, 90s) - CORE DIFFERENTIATOR",
      "deliverables": [
        "backend/services/creative_loop_engine.py (loop logic, ~300 lines)",
        "backend/api/routes/creative.py (API endpoints)",
        "backend/database/models/creative_loop.py (save results)",
        "prompts/creative_loop_templates.yaml (style prompts)",
        "tests/integration/test_creative_loop.py",
        "Documentation: Creative loop guide"
      ],
      "success_criteria": [
        "3 iterations complete in ~90s",
        "All intermediate results saved",
        "Results visually interesting (user testing)",
        "API integration: POST /api/v1/creative/loop"
      ],
      "confidence": 75,
      "dependencies": ["T2-004"],
      "note": "THE core MVP differentiator"
    },
    {
      "id": "T2-006",
      "title": "Calibrate Model Confidence Scores",
      "week": "10-11",
      "priority": "P1_HIGH",
      "agent": "ai_ml_agent_4",
      "description": "Calibrate confidence scores using Platt scaling for CLIP, YOLO, LLaVA",
      "deliverables": [
        "backend/ai/calibration.py (Platt scaling calibrators)",
        "backend/ai/validation_data/ (1000 labeled examples)",
        "scripts/train_calibrators.py (fit calibration curves)",
        "tests/unit/test_calibration.py",
        "Documentation: Calibration report with reliability diagrams"
      ],
      "success_criteria": [
        "Calibrated CLIP: reported 0.90 → actual 0.88-0.92 (within 2%)",
        "Calibrated YOLO: reported 0.80 → actual 0.78-0.82",
        "1000 labeled validation examples",
        "Reliability diagrams plotted"
      ],
      "confidence": 80,
      "dependencies": []
    },
    {
      "id": "T2-007",
      "title": "Integrate Face Recognition API",
      "week": 4,
      "priority": "P1_HIGH",
      "agent": "ai_ml_agent_2",
      "description": "Integrate InsightFace for person-based photo search (GAP FIX from Pass 2)",
      "deliverables": [
        "backend/services/inference/insightface_service.py (face detection + embeddings)",
        "backend/api/routes/search.py (POST /api/v1/search/by_face)",
        "backend/database/qdrant_collections.py (face_embeddings collection)",
        "tests/integration/test_face_search.py",
        "Documentation: Face recognition guide"
      ],
      "success_criteria": [
        "Detect faces >95% accuracy for clear faces",
        "Extract 512-dim embeddings",
        "Store in Qdrant (face_embeddings collection)",
        "API endpoint functional"
      ],
      "confidence": 90,
      "dependencies": []
    }
  ],
  "summary": {
    "total_tasks": 7,
    "total_agents": 5,
    "weeks": "1-11",
    "critical_tasks": 4,
    "high_priority_tasks": 3,
    "core_differentiator": "T2-005 (Creative Loop Engine)",
    "estimated_completion": "Week 11"
  }
}
