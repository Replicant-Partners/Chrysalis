# Uniform Semantic Agent v2.0
# Example: Personal Assistant with Structured Memory (MIRIX style)

apiVersion: usa/v2
kind: Agent

metadata:
  name: structured-personal-assistant
  version: 2.0.0
  description: Personal assistant with structured multi-type memory
  author: uSA Team
  tags:
    - personal-assistant
    - memory-v2
    - structured
    - multi-type-memory

identity:
  role: Personal AI Assistant
  goal: Help with daily tasks while building deep understanding of user
  backstory: |
    I am your personal AI assistant with advanced memory capabilities.
    I maintain separate memory systems for different types of information:
    - Core facts about you
    - Our past conversations
    - General knowledge
    - How to perform tasks
    This structured approach ensures I never confuse facts with experiences.

capabilities:
  tools:
    - name: calendar
      protocol: mcp
      config:
        server: calendar-server
    
    - name: email
      protocol: mcp
      config:
        server: email-server
    
    - name: notes
      protocol: mcp
      config:
        server: notes-server
  
  reasoning:
    strategy: react
    max_iterations: 15
  
  # Structured Memory System (MIRIX style)
  memory:
    architecture: structured  # Separate specialized components
    
    # Working Memory
    working:
      enabled: true
      max_tokens: 8192
      buffer_type: sliding
    
    # Episodic Memory - Specific experiences
    episodic:
      enabled: true
      storage: vector_db
      retention_days: 365  # Keep 1 year of detailed history
      temporal_indexing: true
      metadata_fields:
        - timestamp
        - actor
        - event_type
        - location
        - participants
    
    # Semantic Memory - General knowledge
    semantic:
      enabled: true
      storage: hybrid
      rag:
        enabled: true
        top_k: 3
        min_relevance: 0.8
      knowledge_graph: true
    
    # Procedural Memory - Task procedures
    procedural:
      enabled: true
      storage: structured
      format: json_schema
      versioning: true
    
    # Core Memory - Identity and key facts
    core:
      enabled: true
      self_editing: true
      blocks:
        persona: |
          I am a helpful, friendly personal assistant.
          I focus on being proactive and anticipating needs.
          I maintain professional boundaries while being warm.
        
        user_profile: |
          User: Not yet configured
          Preferences: Learning
          Schedule: Analyzing patterns
        
        active_goals: |
          Current focus areas being tracked.
    
    # Simple but effective embeddings
    embeddings:
      model: openai/text-embedding-3-small
      dimensions: 1536
      batch_size: 50
    
    # Simplified storage for personal use
    storage:
      primary: chroma  # Lightweight vector DB
      vector_db:
        provider: chroma
        collection: personal_assistant_memory
        config:
          path: ${HOME}/.usa/memory/chroma
      
      cache: null  # No cache for personal use
      backup: null
    
    # Operations optimized for personal assistant
    operations:
      retrieval:
        strategy: agentic_rag
        hybrid_search: false  # Simple semantic only
        reranking: false
        max_results: 5
      
      consolidation:
        strategy: periodic
        frequency: daily
        async_processing: true
      
      forgetting:
        enabled: true
        strategy: fifo  # Simple FIFO for old entries
        threshold: 0.5
        parameters:
          max_memories: 10000

protocols:
  mcp:
    enabled: true
    role: client
    servers:
      - name: calendar-server
        command: python
        args:
          - "-m"
          - "mcp_calendar_server"
      
      - name: email-server
        command: python
        args:
          - "-m"
          - "mcp_email_server"
      
      - name: notes-server
        command: python
        args:
          - "-m"
          - "mcp_notes_server"
  
  a2a:
    enabled: false
  
  agent_protocol:
    enabled: true

execution:
  llm:
    provider: openai
    model: gpt-4-turbo-preview
    temperature: 0.7
    max_tokens: 2048
  
  runtime:
    timeout: 120
    max_iterations: 15

deployment:
  context: cli
  environment:
    log_level: info
